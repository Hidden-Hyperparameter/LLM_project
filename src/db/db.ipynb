{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "os.environ['HTTPS_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "os.environ['ALL_PROXY']=\"socks5://Clash:QOAF8Rmd@10.1.0.213:7893\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-jINUrJKhyLbsOjCyFeELT3\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "print(OPENAI_API_KEY[:len(OPENAI_API_KEY)//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024040125_2023040165_2023040163_project  enderlab_db  meta_llama_github\n",
      "CAMELYON16\t\t\t\t  fanxy        model\n",
      "LLM-applications-course\t\t\t  flagged      ollama\n",
      "LLMs\t\t\t\t\t  hf_cache     scripts\n",
      "bch\t\t\t\t\t  huxw\t       wzh\n",
      "ch3\t\t\t\t\t  jzc\t       xtq\n",
      "data\t\t\t\t\t  lab\t       ych\n",
      "dengyaotriangle\t\t\t\t  lab4\t       ynycoding\n",
      "duan\t\t\t\t\t  lab5\t       yuyue\n",
      "dyx\t\t\t\t\t  llm\n",
      "embedding\t\t\t\t  lsy\n"
     ]
    }
   ],
   "source": [
    "!ls /share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "abstract_alg = TextLoader(\"/szhare/2024040125_2023040165_2023040163_project/data/ailab_rdm.md\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading test",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_community/document_loaders/text.py:41\u001b[0m, in \u001b[0;36mTextLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     42\u001b[0m         text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m test_txt \u001b[38;5;241m=\u001b[39m \u001b[43mTextLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_community/document_loaders/text.py:57\u001b[0m, in \u001b[0;36mTextLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     59\u001b[0m metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path}\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [Document(page_content\u001b[38;5;241m=\u001b[39mtext, metadata\u001b[38;5;241m=\u001b[39mmetadata)]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error loading test"
     ]
    }
   ],
   "source": [
    "test = 'test'\n",
    "test_txt = TextLoader(test).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.text.TextLoader at 0x7fd5f85b8310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='# ailab\\n\\n- [ailab](#ailab)\\n  - [集群概况](#集群概况)\\n  - [获取访问权限](#获取访问权限)\\n    - [配置kubeconfig](#配置kubeconfig)\\n  - [使用K8S](#使用k8s)\\n  - [其他使用说明](#其他使用说明)\\n    - [修改账号密码](#修改账号密码)\\n    - [使用 VS Code 连接K8S远程调试](#使用-vs-code-连接k8s远程调试)\\n    - [私有容器镜像仓库](#私有容器镜像仓库)\\n      - [自定义镜像](#自定义镜像)\\n        - [信任集群 Harbor](#信任集群-harbor)\\n        - [制作镜像](#制作镜像)\\n          - [环境准备](#环境准备)\\n          - [编写 Dockerfile 制作镜像](#编写-dockerfile-制作镜像)\\n        - [从自定义镜像创建 Pod](#从自定义镜像创建-pod)\\n\\n\\n## 集群概况\\n\\n本集群计算环境基于 K8S 搭建而成，硬件包括3台独立的 master 节点、28台 worker 节点和一台提供 NFS 服务的 NAS（网络存储服务器）。使用 Harbor 搭建私有镜像仓库，openLDAP 进行统一身份认证。通过统一的 kubeconfig 配置文件分发平台，用户也可以通过 [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/) 以命令行的方式使用K8S集群。\\n\\n\\n|系统|登陆地址|功能|\\n|---|---|---|\\n|密码管理|https://auth.ai.iiis.co:9443|账号修改密码。|\\n|Harbor|https://harbor.ai.iiis.co:9443|私有容器镜像仓库|\\n|kubeconfig|https://login.ai.iiis.co:9443|kubeconfig配置文件分发平台|\\n\\n## 获取访问权限\\n\\n在管理员已经为用户创建好账号的情况下， 用户需要确认是否已经满足下列三个条件\\n\\n- 您使用的终端可以连通SSH跳板机，测试方法为ping js.ai.iiis.co， 如果ping不通，检查你的网络设置（特别是DNS设置），或者联络管理员。\\n- 您已经获取了访问K8S集群的用户名、用户账号关联邮箱和登录密码。\\n- 在等待获取访问权限的过程中，可以先准备好安装本地软件 （见下节）。\\n为了确保账号安全，强烈建议大家拿到账号后先 [修改密码](#修改账号密码)。\\n\\n## 使用SSH跳板机\\n  \\n - 在您使用的终端上执行如下命令：\\n```bash\\n   ssh -i 私钥文件名  -N -L 8443:api.ai.iiis.co:8443 ailab@js.ai.iiis.co -p 9022\\n```\\n私钥文件名默认为~/.ssh/id_rsa (可以省略）\\n - 如果终端上8443端口已经被其他程序占用，可以换成其他端口，比如换成8444端口，则命令应写成：\\n```bash\\n  ssh -i 私钥文件名  -N -L 8444:api.ai.iiis.co:8443 ailab@js.ai.iiis.co -p 9022\\n```\\n - 命令执行后，会出现貌似“卡死”现象（命令并不返回），这是正常的。不要关闭该terminal。可以另打开一个terminal进行其他操作。也可以在上述ssh命令的最后加上&，将放入后台。\\n - 如果您希望自动连接跳板机，可以参考autossh (https://www.harding.motd.ca/autossh/)\\n  \\n## 配置集群访问环境\\n\\n### 安装本地软件\\n\\n本地电脑至少需要安装以下两个软件。\\n\\n#### Kubectl\\n用户可以直接使用 [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/) 管理 k8s。\\n安装说明在 https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/\\n\\n#### Helm\\nhelm 是 Kubernetes 的包管理器，helm的安装及使用方法可以参考[官方文档](https://helm.sh/docs/)。比较简单的安装方式（Linux上）是使用这个脚本\\nhttps://helm.sh/docs/intro/install/#from-script\\n\\n推荐安装以下软件：\\n* Docker （如果你需要本地构建镜像）。 PC上推荐安装docker desktop，有界面使用更方便。 https://www.docker.com/products/docker-desktop/\\n\\n* VSCode （本地集成化开发环境，使用K8S更加方便）。\\n\\n### 配置kubeconfig\\n\\n用户基于 kubeconfig 通过命令行方式使用K8S，需要先在自己的终端设备配置好 kubeconfig。利用系统提供的 kubeconfig 信息（包含用户账户和 Token 等信息），可以在自己的终端利用 kubectl 对 K8S 集群中的资源进行访问。本节介绍如何获取和使用 kubeconfig。\\n\\n用浏览器访问URL地址：https://login.ai.iiis.co:9443，会进入Login界面：\\n\\n![](assets/dex_login.png)\\n\\n输入邮箱地址（邮箱地址等同申请的账号，格式为：用户名@iiis.co）和密码（上边修改过的密码）即可登录。\\n\\n>注：这里的邮箱地址是***用户名@iiis.co***。\\n\\n进入kubeconfig信息页面，选择您使用的系统类型。\\n\\n请按照您所使用的 kubectl 所在的操作系统进行选择。\\n\\n![](assets/dex_token_1.png)\\n\\n接下来，要按照页面指示的顺序在您运行 kubectl 的命令行运行命令。\\n\\n>注：如果你用的是Windows机器，请在Windows Power Shell 下运行这些命令，普通的cmd不识别这种格式的环境变量。\\n\\n可以点击每条命令右上的复制图标来将命令复制到粘贴板。\\n\\n![](assets/dex_token_2.png)\\n\\n所有指令执行完毕后，再运行如下命令设置默认的namespace (ns)。在 K8S 集群中，管理员已经为每一位用户创建了与 UID 相同的命名空间ns。用户只在自己的 ns 中具有使用权限，因此所有操作都只能在自己的 ns 中完成。通过运行下面的命令，可以避免每个命令都需要指定ns。\\n\\n```bash\\nkubectl config set-context --current --namespace=`kubectl config current-context | cut -d\\'-\\' -f 1` \\n```\\n- 修改所获得的kubeconfig文件，把文件内容中的server: https://api.ai.iiis.co:8443 修改成server: https://127.0.0.1:8443。 (或者把server: https://api.ai.iiis.co:8443注释掉，另加一行server: https://127.0.0.1:8443)\\n- 提示：如果连接SSH跳板机时，本地终端使用的端口不是8443，而是其他端口，比如8444，则需要把文件内容中的server: https://api.ai.iiis.co:8443 修改成server: https://127.0.0.1:8444。(或者把server: https://api.ai.iiis.co:8443注释掉，另加一行server: https://127.0.0.1:8444)\\n\\n之后可以使用以下 kubectl 命令测试是否已经可以访问K8S中的资源。\\n\\n```bash\\nkubectl get pvc\\n```\\n应该能看到返回了3个或7个PVC （是用户在集群中可以访问的存储空间，可以理解为是一个盘）。\\n\\n## 使用K8S\\n\\n### 使用默认配置启动计算任务\\n\\n本仓库已经为用户提供了创建计算任务的默认 helm 模板，如果使用默认配置，只需要将 user/values.yaml 文件中的内容按照自己账号和计算需求进行修改，即可使用helm创建计算任务。 user/values-template.yaml 文件的具体内容为：\\n\\n```\\n########### 必须要写的部分 ###########\\nNameSpace: namespace   # 自己的namespace （同用户名）\\nBaseName: pytorch   # 任务的基本名字，建议写任务描述，例如pytorch\\nContainerImage: harbor.ai.iiis.co/xuw/pytorch:v1.5   # 镜像名称，默认为 harbor.ai.iiis.co/xuw/pytorch:v1.5，或者见README的说明\\n\\n########### 选填的部分 ###########\\n# DeployName: namespace-pytorch-release     # 任务（deployment）的名字，默认为`NameSpace-BaseName-ReleaseName`， releaseName为随机生成的字符串是在helm命令行里指定的\\n# Label: pytorch-release              # 任务的标签，默认为`BaseName-ReleaseName`\\n# ContainerName: pytorch-release      # 容器名，默认为`BaseName-ReleaseName`\\n# NVMEStorage: 100G                   # 申请的本地盘/scratch的大小，不填即为默认值\\n# Limits:             # 申请的资源，注意所有启动的资源总和不能超过自己ns的quota，如果增加quota，需要向管理员申请，不填为默认值\\n#  CPU: 8\\n#  memory: 16Gi\\n#  GPU: 0\\n\\n```\\n\\n此文件用于创建一个副本数为 1 的 [Deployment](https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/deployment/)计算任务工作负载。你可以复制这个文件到比如 `cp value-template.yaml lab1.yaml`，然后编辑lab1.yaml文件，输入你的配置参数。之后在user目录中运行\\n\\n```\\ncd user\\nhelm install release_name --values ./lab1.yaml ./userchart\\n```\\n\\n`release_name`为helm部署的版本名（release），建议设置为自己的`UID+任务描述`的格式以方便后续维护管理，例如xuw_lab1。`--values ./lab1.yaml`为helm模板的各项变量提供了对应的值（你刚刚设置的），最后`./userchart`是helm模板的路径位置。\\n\\n之后，可以通过运行 \\n```bash\\nkubectl get pods\\n```\\n来观察启动的pod是否已经启动了。启动之后可以通过\\n\\n```bash\\nkubectl exec -i name_of_the_pod -- bash\\n```\\n来连接这个pod，并且启动bash。建议大家使用后边描述的使用VSCode连接K8S使用，要方便很多。\\n\\n### 默认挂载的存储描述\\n\\n在默认的模板中，自动为每个pod默认挂载了三个存储卷。这些存储卷是管理员为用户创建好了用于长期保存数据的[持久卷申领（PersistentVolumeClaim，PVC）](https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/)。\\n\\n- 挂载于容器内`/root`路径的NFS服务的PVC，用于存储文档及代码等小文件；\\n- 挂载于容器内`/gfshome`路径GFS的个人存储空间PVC，用于存储模型文件、数据集等大文件；\\n- 挂载于容器内`/share`路径GFS的共享空间PVC，用于存放和共享开源大模型、开源数据集等公共数据；\\n\\n临时数据存放在宿主机本地的NVME硬盘中，挂载在容器内的`/scratch1`至`/scratch4`，PVC被删除后里面的数据也会被删除，请一定不要将需要持久化保存的重要数据放在这几个路径。\\n\\n上面的helm模板中会自动挂载长期存储数据的三个PVC，并自动创建对应于`/scratch1`至`/scratch4`的四个临时数据存储PVC。\\n\\n\\n| 存储系统   | 写入速度 |\\n| ---------- | -------- |\\n| 宿主机NVME | 2.3GB/s  |\\n| GFS        | 1GB/s    |\\n| NFS        | 1GB/s    |\\n\\n### 删除计算任务\\n\\n通过下面的命令删除计算任务\\n\\n```\\nhelm delete release_name\\n```\\n其中，release_name是你创建任务时候输入的第一个参数（release_name)，如果你忘了当时用的什么了，可以用\\n```\\nhelm list\\n```\\n来列出所有的release。\\n\\nhelm delete 命令会自动删除容器和应于`/scratch1`至`/scratch4`的四个临时数据存储PVC，但不会删除长期存储数据的三个PVC。\\n\\n\\n### 定制自己的模板\\n\\n如果对helm chart功能及语法比较熟悉，也欢迎用户对模板进行修改或定制，并将成果分享给大家。\\n\\n## 其他使用说明\\n\\n### 修改账号密码\\n\\n集群提供了一套简单的密码修改界面，用户可以修改自己账号的密码。\\n\\n用浏览器访问URL地址 `https://auth.ai.iiis.co:9443` 访问密码修改界面。界面如下图：\\n![](assets/ssp_main_page.png)\\n\\n在界面上填写用户名（界面上的Login字段）、原密码（Old password字段）、新密码（New password字段），并重复输入一次新密码（Confirm字段），点击【Send】按钮，即可完成账号密码修改。\\n![](assets/ssp_success.png)\\n\\n### 使用 VS Code 连接K8S远程调试\\n\\n使用 [VS Code](https://code.visualstudio.com/) 可以远程 debug 集群中创建的 POD。这里我们给出一个简单的教程，更多的信息请自行查阅 [Kubernetes 文档](https://kubernetes.io/zh/docs/concepts/services-networking/service/)与 [VS Code 文档](https://code.visualstudio.com/docs/azure/kubernetes)。\\n\\n首先我们需要在 VS Code 中安装`Kubernetes`插件、`Docker`插件、`Remote Container`插件、`Bridge to Kubernetes`插件：\\n\\n![](assets/vscode/vsc_k8s_plugin.jpg)\\n\\n![](assets/vscode/vsc_docker_plugin.jpg)\\n\\n![](assets/vscode/vsc_remote_connector_plugin.jpg)\\n\\n![](assets/vscode/vsc_k8s_bridge_plugin.jpg)\\n\\n使用`ctrl + shift + P`（Mac 下`command + shift + P`）选择`Kubernetes: Use Namespace`\\n\\n![](assets/vscode/vsc_k8s_select_ns.jpg)\\n\\n输入自己的 namespace 后就能访问自己namespace下的资源了。以连接一个 POD 作为示例：\\n\\n![](assets/vscode/vsc_connect_k8s.jpg)\\n\\n这样将会自动连接一个 VS Code 远程窗口，之后的开发就和本地类似了。\\n\\n### 私有容器镜像仓库\\n\\n#### 自定义镜像\\n\\n我们可以在集群里从自定义镜像拉起 POD，以支持快速的实验环境配置。自定义镜像的思路是**在`ubuntu-tensorflow`、`ubuntu-pytorch`或`orion-client-2.4.2`的基础上，配置自己的环境\\x08**。\\n\\n##### 信任集群 Harbor\\n\\n自定义镜像需要从 Harbor 拉取，因此我们需要在 Docker 中添加对集群 Harbor 的信任。在Mac下用 Docker Desktop 可以直接在客户端`Docker Engine`里加入`insecure-registries`项，若未使用 Docker Desktop，则在`/etc/docker/daemon.json`中添加（若该文件不存在则创建）：\\n\\n```json\\n{\\n\\n  \"insecure-registries\": [\\n    \"harbor.ai.iiis.co\"\\n  ]\\n}\\n```\\n\\n添加完毕后，重启 Docker。\\n\\n##### 制作镜像\\n\\n制作镜像的方式有基于 Dockerfile 和 `docker commit`命令两种形式。我们这里推荐基于 Dockerfile 方式，`docker commit`方式请参考[官方文档](https://docs.docker.com/engine/reference/commandline/commit/)。\\n\\n> **_NOTE:_** 在[这里](https://github.com/iiisthu/gpupool/tree/master/examples/build_example)可以找到我们在这一节所使用的例子。\\n\\n我们假设在`ubuntu-pytorch`的基础上，我们还需要配置一系列环境：\\n\\n1. 安装一系列 Python 依赖库，在`requirements.txt`中指明。\\n2. 将某个 Python 包的 Git 仓库放入镜像，并从仓库源码安装该 Python 包。\\n3. 创建`workspace`工作目录。\\n\\n其他的操作可以参考这几个任务。我们假设我们在`build`目录下工作，我们使用[`navdeep-G/samplemod`](https://github.com/navdeep-G/samplemod)作为 Python Package 的例子。\\n\\n###### 环境准备\\n\\n假设我们需要 Python 支持一系列的库，例如画图的`matplotlib`和交互式的`jupyter`等，我们将这些写在`build`目录下：\\n\\n```txt\\n# requirements.txt\\nnumpy >= 1.19\\nmatplotlib\\npandas >= 1.0\\njupyter\\n```\\n\\n我们也希望pod能安装我们自己的一个私有代码仓库中的某个 Python Package，我们以[`navdeep-G/samplemod`](https://github.com/navdeep-G/samplemod)为例：\\n\\n```bash\\n# PWD: build/\\ngit clone https://github.com/navdeep-G/samplemod\\n```\\n\\n整个工作目录为：\\n\\n```\\nbuild\\n├── samplemod\\n│   ├── docs/\\n│   ├── sample/\\n│   ├── tests/\\n│   ├── .gitignore\\n│   ├── LICENSE\\n│   ├── MANIFEST.in\\n│   ├── Makefile\\n│   ├── README.rst\\n│   ├── requirements.txt\\n│   └── setup.py\\n└── requirements.txt\\n```\\n\\n###### 编写 Dockerfile 制作镜像\\n\\n我们从`harbor.ai.iiis.co:9443/library/`下的镜像出发，安装`requirements.txt`中的依赖，并安装数据。我们这里不赘述[ Dockerfile 的语法](https://docs.docker.com/engine/reference/builder/)。实例的 Dockerfile 如下：\\n\\n```docker\\n# Dockerfile\\nFROM harbor.ai.iiis.co:9443/library/ubuntu-pytorch:1.5.0\\nCOPY . build\\nRUN pip install -r build/requirements.txt && cd build/samplemod; pip install . && mkdir -p workspace && rm -rf build\\n```\\n\\n> **_NOTE:_** 这里用单行命令是为了让制作后的镜像历史中不会存在build文件夹（类似于git，即使删去的文件也会在历史中存储，以备未来可能的恢复）。\\n\\n之后利用`docker`按照 Dockerfile 制作镜像，并标记为`sample:v0`：\\n\\n```bash\\ndocker build . -t sample:v0\\n```\\n\\n最后确认镜像已经成功创建：\\n\\n```\\n$ docker images | grep sample\\nsample          v0         707ab1c88146        30 seconds ago       11.3GB\\n```\\n\\n##### 从自定义镜像创建 Pod\\n\\n从刚才我们制作的镜像创建 Pod 分为两步，首先需要将镜像推送到集群镜像仓库 Harbor，再从 Harbor 对应的镜像拉起 Pod。\\n\\n访问[https://harbor.ai.iiis.co:9443](https://harbor.ai.iiis.co:9443)，注意这里必须是https，用户名及密码等同用户访问k8s集群的用户名及密码。\\n\\n> **_NOTE:_** 注意这里的用户名格式为“用户名@iiis.co”。\\n\\n连接到 Harbor 后新建项目：\\n\\n![](assets/harbor/harbor_dashboard.jpg)\\n\\n![](assets/harbor/harbor_create_project.jpg)\\n\\n> **_NOTE:_** 注意这里需要勾选公开，原因是私有集群物理机的 docker 并没有登录用户个人的 Harbor 账户，因此无法拉取私有仓库中的镜像。\\n\\n假设我们的项目名为 zhangsan，则我们之后的镜像均要 push 到`harbor.ai.iiis.co:9443/zhangsan/`下，首先 tag 我们做好的镜像：\\n\\n```bash\\ndocker tag sample:v0 harbor.ai.iiis.co:9443/zhangsan/sample:v0\\n```\\n\\n之后将镜像 push 到 Harbor 中，我们需要先在 docker 中登录我们在 Harbor上的账号：\\n\\n```txt\\n$ docker logout harbor.ai.iiis.co:9443\\nRemoving login credentials for harbor.ai.iiis.co\\n$ docker login harbor.ai.iiis.co:9443\\nUsername: zhangsan@iiis.co\\nPassword:\\nLogin Succeeded\\n```\\n\\n最后将镜像推送到 Harbor 中：\\n\\n```bash\\ndocker push harbor.ai.iiis.co:9443/zhangsan/sample:v0\\n```\\n\\n创建好镜像后，拉起 Pod 流程和标准镜像一样。\\n', metadata={'source': '/share/2024040125_2023040165_2023040163_project/data/ailab_rdm.md'})]\n"
     ]
    }
   ],
   "source": [
    "print(abstract_alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can have some trials with different chunk_size and chunk_overlap.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(abstract_alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method split_documents in module langchain.text_splitter:\n",
      "\n",
      "split_documents(documents: 'Iterable[Document]') -> 'List[Document]' method of langchain.text_splitter.RecursiveCharacterTextSplitter instance\n",
      "    Split documents.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(text_splitter.split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 25 documents\n",
      "# ailab\n",
      "\n",
      "- [ailab](#ailab)\n",
      "  - [集群概况](#集群概况)\n",
      "  - [获取访问权限](#获取访问权限)\n",
      "    - [配置kubeconfig](#配置kubeconfi\n",
      "=========\n",
      "## 集群概况\n",
      "\n",
      "本集群计算环境基于 K8S 搭建而成，硬件包括3台独立的 master 节点、28台 worker 节点和一台提供 NFS 服务的 NAS（网络存储服务器）。使用 Harbor 搭建\n",
      "=========\n",
      "在管理员已经为用户创建好账号的情况下， 用户需要确认是否已经满足下列三个条件\n",
      "\n",
      "- 您使用的终端可以连通SSH跳板机，测试方法为ping js.ai.iiis.co， 如果ping不通，检查你的网络设\n",
      "=========\n",
      "## 使用SSH跳板机\n",
      "  \n",
      " - 在您使用的终端上执行如下命令：\n",
      "```bash\n",
      "   ssh -i 私钥文件名  -N -L 8443:api.ai.iiis.co:8443 ailab@js.a\n",
      "=========\n",
      "### 安装本地软件\n",
      "\n",
      "本地电脑至少需要安装以下两个软件。\n",
      "\n",
      "#### Kubectl\n",
      "用户可以直接使用 [kubectl](https://kubernetes.io/docs/tasks/tool\n",
      "=========\n",
      "* VSCode （本地集成化开发环境，使用K8S更加方便）。\n",
      "\n",
      "### 配置kubeconfig\n",
      "\n",
      "用户基于 kubeconfig 通过命令行方式使用K8S，需要先在自己的终端设备配置好 kubec\n",
      "=========\n",
      "![](assets/dex_token_1.png)\n",
      "\n",
      "接下来，要按照页面指示的顺序在您运行 kubectl 的命令行运行命令。\n",
      "\n",
      ">注：如果你用的是Windows机器，请在Windows Powe\n",
      "=========\n",
      "```bash\n",
      "kubectl config set-context --current --namespace=`kubectl config current-context | cut -d'-'\n",
      "=========\n",
      "之后可以使用以下 kubectl 命令测试是否已经可以访问K8S中的资源。\n",
      "\n",
      "```bash\n",
      "kubectl get pvc\n",
      "```\n",
      "应该能看到返回了3个或7个PVC （是用户在集群中可以访问的存储空\n",
      "=========\n",
      "```\n",
      "########### 必须要写的部分 ###########\n",
      "NameSpace: namespace   # 自己的namespace （同用户名）\n",
      "BaseName: pytorch  \n",
      "=========\n",
      "########### 选填的部分 ###########\n",
      "# DeployName: namespace-pytorch-release     # 任务（deployment）的名字，默认为`Na\n",
      "=========\n",
      "```\n",
      "\n",
      "此文件用于创建一个副本数为 1 的 [Deployment](https://kubernetes.io/zh-cn/docs/concepts/workloads/controllers/\n",
      "=========\n",
      "之后，可以通过运行 \n",
      "```bash\n",
      "kubectl get pods\n",
      "```\n",
      "来观察启动的pod是否已经启动了。启动之后可以通过\n",
      "\n",
      "```bash\n",
      "kubectl exec -i name_of_t\n",
      "=========\n",
      "临时数据存放在宿主机本地的NVME硬盘中，挂载在容器内的`/scratch1`至`/scratch4`，PVC被删除后里面的数据也会被删除，请一定不要将需要持久化保存的重要数据放在这几个路径。\n",
      "\n",
      "上面\n",
      "=========\n",
      "helm delete 命令会自动删除容器和应于`/scratch1`至`/scratch4`的四个临时数据存储PVC，但不会删除长期存储数据的三个PVC。\n",
      "\n",
      "\n",
      "### 定制自己的模板\n",
      "\n",
      "如果对hel\n",
      "=========\n",
      "### 使用 VS Code 连接K8S远程调试\n",
      "\n",
      "使用 [VS Code](https://code.visualstudio.com/) 可以远程 debug 集群中创建的 POD。这里我们给出一\n",
      "=========\n",
      "![](assets/vscode/vsc_k8s_bridge_plugin.jpg)\n",
      "\n",
      "使用`ctrl + shift + P`（Mac 下`command + shift + P`）选择`Kub\n",
      "=========\n",
      "##### 信任集群 Harbor\n",
      "\n",
      "自定义镜像需要从 Harbor 拉取，因此我们需要在 Docker 中添加对集群 Harbor 的信任。在Mac下用 Docker Desktop 可以直接在客户\n",
      "=========\n",
      "> **_NOTE:_** 在[这里](https://github.com/iiisthu/gpupool/tree/master/examples/build_example)可以找到我们在这一节\n",
      "=========\n",
      "```txt\n",
      "# requirements.txt\n",
      "numpy >= 1.19\n",
      "matplotlib\n",
      "pandas >= 1.0\n",
      "jupyter\n",
      "```\n",
      "\n",
      "我们也希望pod能安装我们自己的一个私有代码\n",
      "=========\n",
      "整个工作目录为：\n",
      "\n",
      "```\n",
      "build\n",
      "├── samplemod\n",
      "│   ├── docs/\n",
      "│   ├── sample/\n",
      "│   ├── tests/\n",
      "│   ├── .gitignore\n",
      "│ \n",
      "=========\n",
      "```docker\n",
      "# Dockerfile\n",
      "FROM harbor.ai.iiis.co:9443/library/ubuntu-pytorch:1.5.0\n",
      "COPY . build\n",
      "RUN pip\n",
      "=========\n",
      "最后确认镜像已经成功创建：\n",
      "\n",
      "```\n",
      "$ docker images | grep sample\n",
      "sample          v0         707ab1c88146        30 s\n",
      "=========\n",
      "![](assets/harbor/harbor_create_project.jpg)\n",
      "\n",
      "> **_NOTE:_** 注意这里需要勾选公开，原因是私有集群物理机的 docker 并没有登录用户个人的\n",
      "=========\n",
      "```txt\n",
      "$ docker logout harbor.ai.iiis.co:9443\n",
      "Removing login credentials for harbor.ai.iiis.co\n",
      "$ doc\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')\n",
    "\n",
    "for t in texts:\n",
    "    print(t.page_content[:100])\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Let's use the local ones.\n",
    "# We have downloaded a number of popular embedding models for you, in the /share/embedding directory, including\n",
    "# LaBSE\n",
    "# all-MiniLM-L12-v2\n",
    "# all-MiniLM-L6-v2\n",
    "# paraphrase-multilingual-MiniLM-L12-v2\n",
    "\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "minilm_embedding = SentenceTransformerEmbeddings(model_name=\"/share/embedding/all-MiniLM-L6-v2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute embeddings and save the embeddings into ChromaDB\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "chroma_dir = \"/scratch2/chroma_db\"\n",
    "docsearch_chroma = Chroma.from_documents(texts, \n",
    "                                         minilm_embedding, \n",
    "                                         collection_name='ailab_readme', \n",
    "                                         persist_directory=chroma_dir,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions from https://en.wikibooks.org/wiki/Muggles%27_Guide_to_Harry_Potter/Books/Philosopher%27s_Stone/Chapter_1\n",
    "# you can try yourself\n",
    "\n",
    "# query = 'Why would the Dursleys consider being related to the Potters a \"shameful secret\"?'\n",
    "# query = 'Who are the robed people Mr. Dursley sees in the streets?'\n",
    "# query = 'What might a \"Muggle\" be?'\n",
    "# query = 'What exactly is the cat on Privet Drive?'\n",
    "query = '''How to check if a pod is running'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A utiity function ...\n",
    "def print_search_results(docs,l=None):\n",
    "    print(f\"search returned %d results. \" % len(docs))\n",
    "    for doc in docs:\n",
    "        if l is None:\n",
    "            print(doc.page_content)\n",
    "        else:\n",
    "            print(doc.page_content[:l])\n",
    "        print(\"=============\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "之后，可以通过运行 \n",
      "```bash\n",
      "kubectl get pods\n",
      "```\n",
      "来观察启动的pod是否已经启动了。启动之后可以通过\n",
      "\n",
      "```bash\n",
      "kubectl exec -i name_of_the_pod -- bash\n",
      "```\n",
      "来连接这个pod，并且启动bash。建议大家使用后边描述的使用VSCode连接K8S使用，要方便很多。\n",
      "\n",
      "### 默认挂载的存储描述\n",
      "\n",
      "在默认的模板中，自动为每个pod默认挂载了三个存储卷。这些存储卷是管理员为用户创建好了用于长期保存数据的[持久卷申领（PersistentVolumeClaim，PVC）](https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/)。\n",
      "\n",
      "- 挂载于容器内`/root`路径的NFS服务的PVC，用于存储文档及代码等小文件；\n",
      "- 挂载于容器内`/gfshome`路径GFS的个人存储空间PVC，用于存储模型文件、数据集等大文件；\n",
      "- 挂载于容器内`/share`路径GFS的共享空间PVC，用于存放和共享开源大模型、开源数据集等公共数据；\n",
      "=============\n",
      "之后，可以通过运行 \n",
      "```bash\n",
      "kubectl get pods\n",
      "```\n",
      "来观察启动的pod是否已经启动了。启动之后可以通过\n",
      "\n",
      "```bash\n",
      "kubectl exec -i name_of_the_pod -- bash\n",
      "```\n",
      "来连接这个pod，并且启动bash。建议大家使用后边描述的使用VSCode连接K8S使用，要方便很多。\n",
      "\n",
      "### 默认挂载的存储描述\n",
      "\n",
      "在默认的模板中，自动为每个pod默认挂载了三个存储卷。这些存储卷是管理员为用户创建好了用于长期保存数据的[持久卷申领（PersistentVolumeClaim，PVC）](https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/)。\n",
      "\n",
      "- 挂载于容器内`/root`路径的NFS服务的PVC，用于存储文档及代码等小文件；\n",
      "- 挂载于容器内`/gfshome`路径GFS的个人存储空间PVC，用于存储模型文件、数据集等大文件；\n",
      "- 挂载于容器内`/share`路径GFS的共享空间PVC，用于存放和共享开源大模型、开源数据集等公共数据；\n",
      "=============\n",
      "## 集群概况\n",
      "\n",
      "本集群计算环境基于 K8S 搭建而成，硬件包括3台独立的 master 节点、28台 worker 节点和一台提供 NFS 服务的 NAS（网络存储服务器）。使用 Harbor 搭建私有镜像仓库，openLDAP 进行统一身份认证。通过统一的 kubeconfig 配置文件分发平台，用户也可以通过 [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/) 以命令行的方式使用K8S集群。\n",
      "\n",
      "\n",
      "|系统|登陆地址|功能|\n",
      "|---|---|---|\n",
      "|密码管理|https://auth.ai.iiis.co:9443|账号修改密码。|\n",
      "|Harbor|https://harbor.ai.iiis.co:9443|私有容器镜像仓库|\n",
      "|kubeconfig|https://login.ai.iiis.co:9443|kubeconfig配置文件分发平台|\n",
      "\n",
      "## 获取访问权限\n",
      "\n",
      "在管理员已经为用户创建好账号的情况下， 用户需要确认是否已经满足下列三个条件\n",
      "=============\n",
      "## 集群概况\n",
      "\n",
      "本集群计算环境基于 K8S 搭建而成，硬件包括3台独立的 master 节点、28台 worker 节点和一台提供 NFS 服务的 NAS（网络存储服务器）。使用 Harbor 搭建私有镜像仓库，openLDAP 进行统一身份认证。通过统一的 kubeconfig 配置文件分发平台，用户也可以通过 [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/) 以命令行的方式使用K8S集群。\n",
      "\n",
      "\n",
      "|系统|登陆地址|功能|\n",
      "|---|---|---|\n",
      "|密码管理|https://auth.ai.iiis.co:9443|账号修改密码。|\n",
      "|Harbor|https://harbor.ai.iiis.co:9443|私有容器镜像仓库|\n",
      "|kubeconfig|https://login.ai.iiis.co:9443|kubeconfig配置文件分发平台|\n",
      "\n",
      "## 获取访问权限\n",
      "\n",
      "在管理员已经为用户创建好账号的情况下， 用户需要确认是否已经满足下列三个条件\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# semantic similarity search\n",
    "\n",
    "docs = docsearch_chroma.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Document in module langchain_core.documents.base:\n",
      "\n",
      "class Document(langchain_core.load.serializable.Serializable)\n",
      " |  Document(page_content: 'str', *, metadata: dict = None, type: Literal['Document'] = 'Document') -> None\n",
      " |  \n",
      " |  Class for storing a piece of text and associated metadata.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Document\n",
      " |      langchain_core.load.serializable.Serializable\n",
      " |      pydantic.v1.main.BaseModel\n",
      " |      pydantic.v1.utils.Representation\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, page_content: 'str', **kwargs: 'Any') -> 'None'\n",
      " |      Pass page_content in as positional or named arg.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  get_lc_namespace() -> 'List[str]' from pydantic.v1.main.ModelMetaclass\n",
      " |      Get the namespace of the langchain object.\n",
      " |  \n",
      " |  is_lc_serializable() -> 'bool' from pydantic.v1.main.ModelMetaclass\n",
      " |      Return whether this class is serializable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'metadata': 'dict', 'page_content': 'str', 'type': ...\n",
      " |  \n",
      " |  __class_vars__ = set()\n",
      " |  \n",
      " |  __config__ = <class 'pydantic.v1.config.Config'>\n",
      " |  \n",
      " |  __custom_root_type__ = False\n",
      " |  \n",
      " |  __exclude_fields__ = None\n",
      " |  \n",
      " |  __fields__ = {'metadata': ModelField(name='metadata', type=dict, requi...\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  __include_fields__ = None\n",
      " |  \n",
      " |  __post_root_validators__ = []\n",
      " |  \n",
      " |  __pre_root_validators__ = []\n",
      " |  \n",
      " |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      " |  \n",
      " |  __schema_cache__ = {}\n",
      " |  \n",
      " |  __signature__ = <Signature (page_content: 'str', *, metadata: di... ty...\n",
      " |  \n",
      " |  __validators__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  __repr_args__(self) -> Any\n",
      " |      Returns the attributes to show in __str__, __repr__, and __pretty__ this is generally overridden.\n",
      " |      \n",
      " |      Can either return:\n",
      " |      * name - value pairs, e.g.: `[('foo_name', 'foo'), ('bar_name', ['b', 'a', 'r'])]`\n",
      " |      * or, just values, e.g.: `[(None, 'foo'), (None, ['b', 'a', 'r'])]`\n",
      " |  \n",
      " |  to_json(self) -> Union[langchain_core.load.serializable.SerializedConstructor, langchain_core.load.serializable.SerializedNotImplemented]\n",
      " |  \n",
      " |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  lc_id() -> List[str] from pydantic.v1.main.ModelMetaclass\n",
      " |      A unique identifier for this class for serialization purposes.\n",
      " |      \n",
      " |      The unique identifier is a list of strings that describes the path\n",
      " |      to the object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  lc_attributes\n",
      " |      List of attribute names that should be included in the serialized kwargs.\n",
      " |      \n",
      " |      These attributes must be accepted by the constructor.\n",
      " |  \n",
      " |  lc_secrets\n",
      " |      A map of constructor argument names to secret ids.\n",
      " |      \n",
      " |      For example,\n",
      " |          {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from langchain_core.load.serializable.Serializable:\n",
      " |  \n",
      " |  Config = <class 'langchain_core.load.serializable.Serializable.Config'...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __eq__(self, other: Any) -> bool\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getstate__(self) -> 'DictAny'\n",
      " |  \n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      so `dict(model)` works\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state: 'DictAny') -> None\n",
      " |  \n",
      " |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      " |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      " |      \n",
      " |      :param include: fields to include in new model\n",
      " |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      " |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      " |          the new model: you should trust this data\n",
      " |      :param deep: set to `True` to make a deep copy of the model\n",
      " |      :return: new model instance\n",
      " |  \n",
      " |  dict(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> 'DictStrAny'\n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |  \n",
      " |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> str\n",
      " |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      " |      \n",
      " |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __get_validators__() -> 'CallableGenerator' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
      " |      Same as update_forward_refs but will not raise exception\n",
      " |      when forward references are not defined.\n",
      " |  \n",
      " |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      " |  \n",
      " |  from_orm(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_file(path: Union[str, pathlib.Path], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_obj(obj: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  parse_raw(b: Union[str, bytes], *, content_type: str = None, encoding: str = 'utf8', proto: pydantic.v1.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  schema(by_alias: bool = True, ref_template: str = '#/definitions/{model}') -> 'DictStrAny' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  schema_json(*, by_alias: bool = True, ref_template: str = '#/definitions/{model}', **dumps_kwargs: Any) -> str from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  update_forward_refs(**localns: Any) -> None from pydantic.v1.main.ModelMetaclass\n",
      " |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      " |  \n",
      " |  validate(value: Any) -> 'Model' from pydantic.v1.main.ModelMetaclass\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.v1.main.BaseModel:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __fields_set__\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.v1.utils.Representation:\n",
      " |  \n",
      " |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __repr_name__(self) -> str\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |  \n",
      " |  __repr_str__(self, join_str: str) -> str\n",
      " |  \n",
      " |  __rich_repr__(self) -> 'RichReprResult'\n",
      " |      Get fields for Rich library\n",
      " |  \n",
      " |  __str__(self) -> str\n",
      " |      Return str(self).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import langchain_core\n",
    "help(langchain_core.documents.base.Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to local disk\n",
    "docsearch_chroma.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from disk\n",
    "docsearch_chroma_reloaded = Chroma(persist_directory = chroma_dir,\n",
    "                                   collection_name = 'absrst_100_page', \n",
    "                                   embedding_function = minilm_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "If G acts on a set B and distinct elements of G induce distinct permutations of \n",
      "B, the action is said to be faithful. A faithful action is therefore one in which the \n",
      "associated permutation representation is injective. \n",
      "The kernel of the action of G on B is defined to be {g € G | gb = b forallb € B}, \n",
      "namely the elements of G which fix all the elements of B. For the trivial action, the \n",
      "kernel of the action is all of G and this action is not faithful when |G| > 1.\n",
      "=============\n",
      "action is called the left regular action of G on itself. By the cancellation laws, this \n",
      "action is faithful (check this). \n",
      "Other examples of actions are given in the exercises. we \n",
      "10. \n",
      "44 EXERCISES \n",
      ". Let F bea field. Show that the multiplicative group of nonzero elements of F (denoted \n",
      "by F™) acts on the set F by g-a = ga, where g € F“,a € F and ga is the usual product \n",
      "in F of the two field elements (state clearly which axioms in the definition of a field are \n",
      "used).\n",
      "=============\n",
      "parentheses (note that, for example, the 2-tuples (1,2) and (2,1) are different even though \n",
      "the sets {1, 2} and {2, 1} are the same, so the sets being acted upon are different). \n",
      "With reference to the preceding two exercises determine: \n",
      "(a) for which values of k the action of §,, on k-element subsets is faithful, and \n",
      "(b) for which values of k the action of S,, on ordered k-tuples is faithful. \n",
      "Chap.1 Introduction to Groups\n",
      "11. \n",
      "12. \n",
      "17. \n",
      "18. \n",
      "19. \n",
      "20. \n",
      "21. \n",
      "22. \n",
      "23.\n",
      "=============\n",
      ". Prove that the kernel of an action of the group G onthe set A is the same as the kernel of \n",
      "the corresponding permutation representation G — Sy (cf. Exercise 14 in Section 6). \n",
      ". Prove that a group G acts faithfully on a set A if and only if the kernel of the action is the \n",
      "set consisting only of the identity. \n",
      ". Prove that in Example 2 in this section the action is faithful. \n",
      ". Let A bea nonempty set and let k be a positive integer with k < |A|. The symmetric group\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# you can test with the previous or another query\n",
    "\n",
    "query = 'What is the definition of faithful actions'\n",
    "docs = docsearch_chroma_reloaded.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "11. \n",
      "12. \n",
      "17. \n",
      "18. \n",
      "19. \n",
      "20. \n",
      "21. \n",
      "22. \n",
      "23. \n",
      "Sec Write out the cycle decomposition of the eight permutations in S4 corresponding to the \n",
      "elements of Dg given by the action of Dg on the vertices of a square (where the vertices \n",
      "of the square are labelled as in Section 2). \n",
      "Assume n is an even positive integer and show that D2, acts on the set consisting of pairs \n",
      "of opposite vertices of a regular n-gon. Find the kernel of this action (label vertices as \n",
      "usual).\n",
      "=============\n",
      ". Write out the cycle decomposition of each element of order 2 in S4. \n",
      ". Prove that if Q = {1, 2, 3, ...} then Sg is an infinite group (do not say oo! = ov). \n",
      ". (a) Let o be the 12-cycle (1 23 45 678910 11 12). For which positive integers i is \n",
      "o' also a 12-cycle? . \n",
      "(b) Let t be the 8-cycle (1 2 3 45 6 7 8). For which positive integers i is t' also an \n",
      "8-cycle? \n",
      "(c) Let w be the 14-cycle (123456789 10 11 12 13 14). For which positive integers \n",
      "iis a alsoa 14-cycle?\n",
      "=============\n",
      "llr 8 12-7 Br 4 14r 1 15 Fe 13. \n",
      "2 Find the cycle decompositions of the following permutations: o, t, 07, oT, to, and to. \n",
      ". For each of the permutations whose cycle decompositions were computed in the preceding \n",
      "two exercises compute its order. \n",
      ". Compute the order of each of the elements in the following groups: (a) $3 (b) Sq. \n",
      ". Find the order of (1 12 8 10 4)(2 13)(5 11 7)(6 9). \n",
      ". Write out the cycle decomposition of each element of order 4 in S4.\n",
      "=============\n",
      ". Prove that the subgroup generated by any two distinct elements of order 2 in S3 is all of \n",
      "S3. \n",
      ". Prove that the subgroup of S4 generated by (1 2) and (1 2)(3 4) is a noncyclic group of \n",
      "order 4. \n",
      ". Prove that the subgroup of Sq generated by (1 2) and (1 3)(2 4) is isomorphic to the \n",
      "dihedral group of order 8. \n",
      ". Prove that S4 = ((123 4), (124 3)). \n",
      ". Prove that SL2(F3) is the subgroup of GL2(F3) generated by ( ; ; ) and ( 1 i) [Re- \n",
      "1 1 1\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# you can test with the previous or another query\n",
    "\n",
    "query = 'D8 is generated by two cycles of S4 in which question of homework'\n",
    "docs = docsearch_chroma_reloaded.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
