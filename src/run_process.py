import os
import threading
import subprocess
import json

from utils.others import gen_10_pages,encode
from utils.ocr import OCR,TMP_DIR
from db.db import make_db_from_text
LOG_DIR = '/ssdshare/.it/files.json'
lock = threading.Lock()

def query_llm(texts:str):
    """
    Input: texts in first 10 pages
    Output: tags generated by LLM, formatted as a List
    """
    # ##############################################################################
    # #                  TODO: You need to complete the code here                  #
    # ##############################################################################
    # import os
    # Full = "Give me some(about 20) tags based on the context below, without any other things!\n"+texts
    # with open('Query.txt', 'w') as f:
    #     f.write(Full)
    # os.system("cat Query.txt | /share/ollama/ollama run llama3:70b | tee Query.tag")
    # texts = []
    # with open('Query.tag', 'r') as f:
    #     lines = f.readlines()
    #     for line in lines:
    #         # check if it starts with a number
    #         if line[0].isdigit():
    #             texts.append(line.split(' ')[1:].replace('\n',''))
    # ##############################################################################
    # #                              END OF YOUR CODE                              #
    # ##############################################################################
    return 'None'

def full_nopdf(file:str,quiet):
    file = os.path.abspath(file)
    texts = OCR(file,quiet=quiet)
    tags = query_llm(texts)
    with lock:
        if not os.path.exists(LOG_DIR):
            open(LOG_DIR,'w').write(r'{}')
        dic = json.load(open(LOG_DIR))
        assert file not in dic, '[PROCESS]:file already processed'
        dic[file]=tags
        json.dump(dic,open(LOG_DIR,'w'))
    make_db_from_text(file,texts,quiet=quiet)
    

def full_pdf(file:str,quiet):
    out_path = os.path.join(TMP_DIR,encode(file)+'_10pages.pdf')
    gen_10_pages(file,out_path=out_path)
    out_path = os.path.abspath(out_path)
    texts = OCR(out_path,quiet=quiet)
    os.remove(out_path)
    tags = query_llm(texts)
    with lock:
        if not os.path.exists(LOG_DIR):
            open(LOG_DIR,'w').write(r'{}')
        dic = json.load(open(LOG_DIR))
        assert file not in dic, '[PROCESS]:file already processed'
        dic[file]=tags
        json.dump(dic,open(LOG_DIR,'w'))
        
def make_db(file:str,ocr_log_dir:str,quiet):
    print('[MAKE DB]',file,ocr_log_dir,quiet)
    devnull = open(os.devnull,'w')
    if quiet:
        subprocess.run(['python','./ocr_process.py','--file','\"'+file+'\"','--log-dir','\"'+ocr_log_dir+'\"'],stderr=devnull,stdout=devnull)
    else:
        subprocess.run(['python','./ocr_process.py','--file','\"'+file+'\"','--log-dir','\"'+ocr_log_dir+'\"'])


READABLES = ['.jpg', '.jpeg', '.png','.py', '.txt', '.cpp', '.tex', '.md', '.java', '.html', '.css','.sh','.bat']

def run(root_dir = './tests/data/hierarchical_data_simple',ocr_log_dir='./tests/data/process_out.txt',quiet=True):
    def check_suffix(s,c):
        for i in c:
            if s.endswith(i):
                return True
        return False
    l = os.walk(root_dir)
    threads = []
    failures = []
    # first spread out threads to create tags
    for dirname,dirs,files in l:
        print(dirname,dirs,files)
        for file in files:
            if not quiet:   
                print(f'[RUN_PROCESS]:Starting Generating Tags on {file}')
            if check_suffix(file,READABLES):
                thread = threading.Thread(target=full_nopdf,args=(os.path.join(dirname,file),quiet))
            else:
                full_path = os.path.join(dirname,file)
                thread = threading.Thread(target=full_pdf,args=(full_path,quiet))
                failures.append(full_path)
            thread.start()
            threads.append((thread,file))
    for thread,name in threads:
        thread.join()
        if not quiet:   
            print(f'[RUN_PROCESS]: Generating Tags on {name} finished')
    # then spread out no-returning threads for OCR & chroma db, and make logs
    for file in failures:
        print(f'[RUN_PROCESS]: OCR on {file} beginning....')
        thread = threading.Thread(target=make_db,args=(file,ocr_log_dir,quiet))
        thread.start()

if __name__ == '__main__':
    run(quiet=False)
